# data_collection
For this challenge we dealt with two different jupyter notebooks in order to get information for our trip to mars.
Deliverable 1: A Jupyter notebook containing code that scrapes the Mars news titles and preview text.
Deliverable 2: A Jupyter notebook containing code that scrapes the Mars weather data and that cleans, visualizes, and analyzes that data.
Using pandas, matplotlib, chromedriver and many other tools in order to extract information from a site.
Background

You’re now ready to take on a full web-scraping and data analysis project. You’ve learned to identify HTML elements on a page, identify their id and class attributes, and use this knowledge to extract information via both automated browsing with Splinter and HTML parsing with Beautiful Soup. You’ve also learned to scrape various types of information. These include HTML tables and recurring elements, like multiple news articles on a webpage.
As you work on this Challenge, remember that you’re strengthening the same core skills that you’ve been developing until now: collecting data, organizing and storing data, analyzing data, and then visually communicating your insights.
Thanks to splinter and beautiful soup, these tools helped us get the job done as well as make it easier to extract information.
Had help from tutor and ask cbs.
